<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://esinew.github.io/</id>
    <title>每一步都是新生</title>
    <updated>2020-07-09T12:21:50.205Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://esinew.github.io/"/>
    <link rel="self" href="https://esinew.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://esinew.github.io/images/avatar.png</logo>
    <icon>https://esinew.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 每一步都是新生</rights>
    <entry>
        <title type="html"><![CDATA[G1收集器与ZGC收集器]]></title>
        <id>https://esinew.github.io/post/g1-shou-ji-qi-yu-zgc-shou-ji-qi/</id>
        <link href="https://esinew.github.io/post/g1-shou-ji-qi-yu-zgc-shou-ji-qi/">
        </link>
        <updated>2020-07-09T12:15:11.000Z</updated>
        <content type="html"><![CDATA[<p>转载：云大的博客https://www.wangxinshuo.cn/2018/09/09/g1%E6%94%B6%E9%9B%86%E5%99%A8%E4%B8%8Ezgc%E6%94%B6%E9%9B%86%E5%99%A8/</p>
<p>G1收集器<br>
前言</p>
<p>具有的特性：</p>
<ul>
<li>
<p>像CMS收集器一样能够进行并发执行</p>
</li>
<li>
<p>不牺牲大量的吞吐性能</p>
</li>
<li>
<p>不需要更大的Heap</p>
</li>
<li>
<p>可预测的GC时间<br>
与CMS相比具有以下优点：</p>
</li>
<li>
<p>G1会在GC过程中进行整理内存，因此不会产生太多内存碎片</p>
</li>
<li>
<p>G1的STW（Stop The World）更可控，用户可以指定可期望的GC停顿时间<br>
G1中的重要概念<br>
Region</p>
<p>传统的内存划分为新生代、老年代、永久代（在JDK8中以metaspace取而代之）<br>
传统内存区域划分<br>
在G1中将内存区域划分为多个不连续的区域（Region），每个Region内部是连续的。<br>
G1收集器内存划分<br>
<img src="https://esinew.github.io//post-images/1594297078292.png" alt="" loading="lazy"><br>
在上图中，我们注意到还有一些Region标明了H，它代表Humongous，这表示这些Region存储的是巨大对象（humongous object，H-obj），即大小大于等于region一半的对象。<br>
一个Region的大小可以通过参数-XX:G1HeapRegionSize设定，取值范围从1M到32M，且是2的指数。如果不设定，那么G1会根据Heap大小自动决定。</p>
</li>
</ul>
<p>SATB</p>
<p>全称是Snapshot-At—The-Beginning，译为：GC回收前（存活对象）快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。<br>
三色标记法</p>
<pre><code>白：对象没有被标记到，标记阶段结束后，会被当做垃圾回收掉。
灰：对象被标记了，但是它的field还没有被标记或标记完。
黑：对象被标记了，且它的所有field也被标记完了。
</code></pre>
<p>RSet</p>
<p>全称是Remembered Set，是辅助GC过程的一种结构，典型的空间换时间工具，和Card Table有些类似。还有一种数据结构也是辅助GC的：Collection Set（CSet），它记录了GC要收集的Region集合，集合里的Region可以是任意年代的。在GC的时候，对于old-&gt;young和old-&gt;old的跨代对象引用，只要扫描对应的CSet中的RSet即可。逻辑上说每个Region都有一个RSet，RSet记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）。而Card Table则是一种points-out（我引用了谁的对象）的结构，每个Card 覆盖一定范围的Heap（一般为512Bytes）。G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。 这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。<br>
下图表示了RSet、Card和Region的关系<br>
<img src="https://esinew.github.io//post-images/1594297180298.jpg" alt="" loading="lazy"><br>
Pause Prediction Model</p>
<p>G1 GC是一个响应时间优先的GC算法，它与CMS最大的不同是，用户可以设定整个GC过程的期望停顿时间，参数-XX:MaxGCPauseMillis指定一个G1收集过程目标停顿时间，默认值200ms，不过它不是硬性条件，只是期望值。那么G1怎么满足用户的期望呢？就需要这个停顿预测模型了。G1根据这个模型统计计算出来的历史数据来预测本次收集需要选择的Region数量，从而尽量满足用户设定的目标停顿时间。停顿预测模型是以衰减标准偏差为理论基础实现的：</p>
<p>//  share/vm/gc_implementation/g1/g1CollectorPolicy.hpp<br>
double get_new_prediction(TruncatedSeq* seq) {<br>
return MAX2(seq-&gt;davg() + sigma() * seq-&gt;dsd(),<br>
seq-&gt;davg() * confidence_factor(seq-&gt;num()));<br>
}<br>
/*<br>
在这个预测计算公式中：davg表示衰减均值，sigma()返回一个系数，表示信赖度，dsd表示衰减标准偏差，confidence_factor表示可信度相关系数。而方法的参数TruncateSeq，顾名思义，是一个截断的序列，它只跟踪了序列中的最新的n个元素。<br>
*/</p>
<p>Young GC</p>
<p>Young GC：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。<br>
Mixed GC</p>
<p>Mixed GC：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。<br>
由上面的描述可知，Mixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。<br>
ZGC收集器<br>
简介</p>
<p>Z垃圾收回器，也被称为 ZGC, 是一种可伸缩的低延迟垃圾收集器。<br>
目标</p>
<pre><code>垃圾回收停顿时间不超过10ms
无论是相对小的堆(几百MB)还是大堆(TB级)都能应对自如
与G1相比，吞吐量下降不超过15%
方便日后在此基础上实现新的gc特性、利用colored pointers(译者注：暂时翻译为彩色指针)和读屏障进一步优化收集器
</code></pre>
<p>ZGC描述</p>
<p>大体上来说，ZGC是一种并发的、不分代的、基于Region且支持NUMA的压缩收集器。因为只会在枚举根节点的阶段STW, 因此停顿时间不会随着堆大小或存活对象的多少而增加。</p>
<p>ZGC的一个核心设计就是读屏障与彩色指针(colored object pointers, 缩写, colored oops)组合起来使用总体来说是一种利用64位指针中未使用的bit来保存元数据的指针)。这是ZGC可以与用户线程并发执行的原因。从Java的线程角度来看，读取Java对应中的引用变量的操作属于一种读屏障。与单纯的取对象内存地址相比，使用读屏障可以利用彩色指针中包含的信息来决定在允许Java线程读取指针的地址值之前是否需要执行一些操作。例如，对象可能被垃圾收集器移动过了，这时读屏障就可以感知到这种情况并执行一些必要的行为。</p>
<p>跟其它的可选方案相比，我们认为使用彩色指针模式有一些非常吸引人的优势，比如：<br>
– 这允许我们在移动对象/整理内存阶段，在指向可回收/重用区域的指针确定之前回收/重用这部分内存。(原文: It allows us to reclaim and reuse memory during the relocation/compaction phase, before pointers pointing into the reclaimed/reused regions have been fixed.)。这有利于降低堆的开销。这同时也意味着我们不需要再实现一个单独的标记-整理算法用于处理Full GC。<br>
– 这允许我们使用相对来说更少量、更简单的GC屏障。这可以降低JVM运行时的性能开销。同时也可以让JVM字节码解释器和JIT编译器中的GC代码更加容易实现和优化。<br>
– 我们目前会在彩色指针中保存与标记和重定位相关的数据。不过，只要彩色指针中还有足够的未使用的bit, 我们还可以在里面存储更多对读屏障有用的信息。我们认为这为未来实现更多的特性奠定了良好的基础。比如，在复杂多变的内存环境下，我们可以在彩色指针中存储一些追踪信息来让垃圾回收器在移动对象时能将低频次使用的对象移动到不常访问的内存区域(译者注：原文为 cold storage)。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java面试常考的 BIO，NIO，AIO 总结]]></title>
        <id>https://esinew.github.io/post/java-mian-shi-chang-kao-de-bionioaio-zong-jie/</id>
        <link href="https://esinew.github.io/post/java-mian-shi-chang-kao-de-bionioaio-zong-jie/">
        </link>
        <updated>2020-07-08T13:59:37.000Z</updated>
        <content type="html"><![CDATA[<p>转载：JavaGuide<br>
目录：</p>
<pre><code>1. BIO (Blocking I/O)

    1.1 传统 BIO

    1.2 伪异步 IO

    1.3 代码示例

    1.4 总结

2. NIO (New I/O)

    2.1 NIO 简介

    2.2 NIO的特性/NIO与IO区别

        1)Non-blocking IO（非阻塞IO）

        2)Buffer(缓冲区)

        3)Channel (通道)

        4)Selectors(选择器)

    2.3 NIO 读数据和写数据方式

    2.4 NIO核心组件简单介绍

    2.5 代码示例

3. AIO (Asynchronous I/O)

参考
</code></pre>
<p>BIO,NIO,AIO 总结</p>
<p>Java 中的 BIO、NIO和 AIO 理解为是 Java 语言对操作系统的各种 IO 模型的封装。程序员在使用这些 API 的时候，不需要关心操作系统层面的知识，也不需要根据不同操作系统编写不同的代码。只需要使用Java的API就可以了。</p>
<p>在讲 BIO,NIO,AIO 之前先来回顾一下这样几个概念：同步与异步，阻塞与非阻塞。</p>
<p>同步与异步</p>
<pre><code>同步： 同步就是发起一个调用后，被调用者未处理完请求之前，调用不返回。

异步： 异步就是发起一个调用后，立刻得到被调用者的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常依靠事件，回调等机制来通知调用者其返回结果。
</code></pre>
<p>同步和异步的区别最大在于异步的话调用者不需要等待处理结果，被调用者会通过回调等机制来通知调用者其返回结果。</p>
<p>阻塞和非阻塞</p>
<pre><code>阻塞： 阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。

非阻塞： 非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。
</code></pre>
<p>那么同步阻塞、同步非阻塞和异步非阻塞又代表什么意思呢？</p>
<p>举个生活中简单的例子，你妈妈让你烧水，小时候你比较笨啊，在哪里傻等着水开（同步阻塞）。等你稍微再长大一点，你知道每次烧水的空隙可以去干点其他事，然后只需要时不时来看看水开了没有（同步非阻塞）。后来，你们家用上了水开了会发出声音的壶，这样你就只需要听到响声后就知道水开了，在这期间你可以随便干自己的事情，你需要去倒水了（异步非阻塞）。</p>
<ol>
<li>BIO (Blocking I/O)</li>
</ol>
<p>同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。<br>
1.1 传统 BIO</p>
<p>BIO通信（一请求一应答）模型图如下(图源网络，原出处不明)：</p>
<p>采用 BIO 通信模型 的服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接。我们一般通过在 while(true) 循环中服务端会调用 accept() 方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成， 不过可以通过多线程来支持多个客户端的连接，如上图所示。</p>
<p>如果要让 BIO 通信模型 能够同时处理多个客户端请求，就必须使用多线程（主要原因是 socket.accept()、 socket.read()、 socket.write() 涉及的三个主要函数都是同步阻塞的），也就是说它在接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。这就是典型的 一请求一应答通信模型 。我们可以设想一下如果这个连接不做任何事情的话就会造成不必要的线程开销，不过可以通过 线程池机制 改善，线程池还可以让线程的创建和回收成本相对较低。使用FixedThreadPool 可以有效的控制了线程的最大数量，保证了系统有限的资源的控制，实现了N(客户端请求数量):M(处理客户端请求的线程数量)的伪异步I/O模型（N 可以远远大于 M），下面一节&quot;伪异步 BIO&quot;中会详细介绍到。</p>
<p>我们再设想一下当客户端并发访问量增加后这种模型会出现什么问题？</p>
<p>在 Java 虚拟机中，线程是宝贵的资源，线程的创建和销毁成本很高，除此之外，线程的切换成本也是很高的。尤其在 Linux 这样的操作系统中，线程本质上就是一个进程，创建和销毁线程都是重量级的系统函数。如果并发访问量增加会导致线程数急剧膨胀可能会导致线程堆栈溢出、创建新线程失败等问题，最终导致进程宕机或者僵死，不能对外提供服务。<br>
1.2 伪异步 IO</p>
<p>为了解决同步阻塞I/O面临的一个链路需要一个线程处理的问题，后来有人对它的线程模型进行了优化一一一后端通过一个线程池来处理多个客户端的请求接入，形成客户端个数M：线程池最大线程数N的比例关系，其中M可以远远大于N.通过线程池可以灵活地调配线程资源，设置线程的最大值，防止由于海量并发接入导致线程耗尽。</p>
<p>伪异步IO模型图(图源网络，原出处不明)：</p>
<p>采用线程池和任务队列可以实现一种叫做伪异步的 I/O 通信框架，它的模型图如上图所示。当有新的客户端接入时，将客户端的 Socket 封装成一个Task（该任务实现java.lang.Runnable接口）投递到后端的线程池中进行处理，JDK 的线程池维护一个消息队列和 N 个活跃线程，对消息队列中的任务进行处理。由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。</p>
<p>伪异步I/O通信框架采用了线程池实现，因此避免了为每个请求都创建一个独立线程造成的线程资源耗尽问题。不过因为它的底层任然是同步阻塞的BIO模型，因此无法从根本上解决问题。<br>
1.3 代码示例</p>
<p>下面代码中演示了BIO通信（一请求一应答）模型。我们会在客户端创建多个线程依次连接服务端并向其发送&quot;当前时间+:hello world&quot;，服务端会为每个客户端线程创建一个线程来处理。代码示例出自闪电侠的博客，原地址如下：</p>
<p>https://www.jianshu.com/p/a4e03835921a</p>
<p>客户端</p>
<pre><code>/**
*
* @author 闪电侠
* @date 2018年10月14日
* @Description:客户端
*/
 
public class IOClient {
 
 
 
   public static void main(String[] args) {
 
       // TODO 创建多个线程，模拟多个客户端连接服务端
 
       new Thread(() -&gt; {
 
           try {
 
               Socket socket = new Socket(&quot;127.0.0.1&quot;, 3333);
 
               while (true) {
 
                   try {
 
                       socket.getOutputStream().write((new Date() + &quot;: hello world&quot;).getBytes());
 
                       Thread.sleep(2000);
 
                   } catch (Exception e) {
 
                   }
 
               }
 
           } catch (IOException e) {
 
           }
 
       }).start();
 
 
 
   }
 
 
 
}
</code></pre>
<p>服务端</p>
<pre><code>/**
* @author 闪电侠
* @date 2018年10月14日
* @Description: 服务端
*/
 
public class IOServer {
 
 
 
   public static void main(String[] args) throws IOException {
 
       // TODO 服务端处理客户端连接请求
 
       ServerSocket serverSocket = new ServerSocket(3333);
 
 
 
       // 接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理
 
       new Thread(() -&gt; {
 
           while (true) {
 
               try {
 
                   // 阻塞方法获取新的连接
 
                   Socket socket = serverSocket.accept();
 
 
 
                   // 每一个新的连接都创建一个线程，负责读取数据
 
                   new Thread(() -&gt; {
 
                       try {
 
                           int len;
 
                           byte[] data = new byte[1024];
 
                           InputStream inputStream = socket.getInputStream();
 
                           // 按字节流方式读取数据
 
                           while ((len = inputStream.read(data)) != -1) {
 
                               System.out.println(new String(data, 0, len));
 
                           }
 
                       } catch (IOException e) {
 
                       }
 
                   }).start();
 
 
 
               } catch (IOException e) {
 
               }
 
 
 
           }
 
       }).start();
 
 
 
   }
 
 
 
}
</code></pre>
<p>1.4 总结</p>
<p>在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。<br>
2. NIO (New I/O)<br>
2.1 NIO 简介</p>
<p>NIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。</p>
<p>NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。<br>
2.2 NIO的特性/NIO与IO区别</p>
<p>如果是在面试中回答这个问题，我觉得首先肯定要从 NIO 流是非阻塞 IO 而 IO 流是阻塞 IO 说起。然后，可以从 NIO 的3个核心组件/特性为 NIO 带来的一些改进来分析。如果，你把这些都回答上了我觉得你对于 NIO 就有了更为深入一点的认识，面试官问到你这个问题，你也能很轻松的回答上来了。</p>
<p>1)Non-blocking IO（非阻塞IO）</p>
<p>IO流是阻塞的，NIO流是不阻塞的。</p>
<p>Java NIO使我们可以进行非阻塞IO操作。比如说，单线程中从通道读取数据到buffer，同时可以继续做别的事情，当数据读取到buffer中后，线程再继续处理数据。写数据也是一样的。另外，非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。</p>
<p>Java IO的各种流是阻塞的。这意味着，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了</p>
<p>2)Buffer(缓冲区)</p>
<p>IO 面向流(Stream oriented)，而 NIO 面向缓冲区(Buffer oriented)。</p>
<p>Buffer是一个对象，它包含一些要写入或者要读出的数据。在NIO类库中加入Buffer对象，体现了新库与原I/O的一个重要区别。在面向流的I/O中·可以将数据直接写入或者将数据直接读到 Stream 对象中。虽然 Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区，而 NIO 却是直接读到 Buffer 中进行操作。</p>
<p>在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的; 在写入数据时，写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。</p>
<p>最常用的缓冲区是 ByteBuffer,一个 ByteBuffer 提供了一组功能用于操作 byte 数组。除了ByteBuffer,还有其他的一些缓冲区，事实上，每一种Java基本类型（除了Boolean类型）都对应有一种缓冲区。</p>
<p>3)Channel (通道)</p>
<p>NIO 通过Channel（通道） 进行读写。</p>
<p>通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因为 Buffer，通道可以异步地读写。</p>
<p>4)Selectors(选择器)</p>
<p>NIO有选择器，而IO没有。</p>
<p>选择器用于使用单个线程处理多个通道。因此，它需要较少的线程来处理这些通道。线程之间的切换对于操作系统来说是昂贵的。 因此，为了提高系统效率选择器是有用的。</p>
<p>2.3 NIO 读数据和写数据方式</p>
<p>通常来说NIO中的所有IO都是从 Channel（通道） 开始的。</p>
<pre><code>从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据。

从通道进行数据写入 ：创建一个缓冲区，填充数据，并要求通道写入数据。
</code></pre>
<p>数据读取和写入操作图示：</p>
<p>2.4 NIO核心组件简单介绍</p>
<p>NIO 包含下面几个核心的组件：</p>
<pre><code>Channel(通道)

Buffer(缓冲区)

Selector(选择器)
</code></pre>
<p>整个NIO体系包含的类远远不止这三个，只能说这三个是NIO体系的“核心API”。我们上面已经对这三个概念进行了基本的阐述，这里就不多做解释了。<br>
2.5 代码示例</p>
<p>代码示例出自闪电侠的博客，原地址如下：</p>
<p>https://www.jianshu.com/p/a4e03835921a</p>
<p>客户端 IOClient.java 的代码不变，我们对服务端使用 NIO 进行改造。以下代码较多而且逻辑比较复杂，大家看看就好。</p>
<pre><code>/**
*
* @author 闪电侠
* @date 2019年2月21日
* @Description: NIO 改造后的服务端
*/
 
public class NIOServer {
 
   public static void main(String[] args) throws IOException {
 
       // 1. serverSelector负责轮询是否有新的连接，服务端监测到新的连接之后，不再创建一个新的线程，
 
       // 而是直接将新连接绑定到clientSelector上，这样就不用 IO 模型中 1w 个 while 循环在死等
 
       Selector serverSelector = Selector.open();
 
       // 2. clientSelector负责轮询连接是否有数据可读
 
       Selector clientSelector = Selector.open();
 
 
 
       new Thread(() -&gt; {
 
           try {
 
               // 对应IO编程中服务端启动
 
               ServerSocketChannel listenerChannel = ServerSocketChannel.open();
 
               listenerChannel.socket().bind(new InetSocketAddress(3333));
 
               listenerChannel.configureBlocking(false);
 
               listenerChannel.register(serverSelector, SelectionKey.OP_ACCEPT);
 
 
 
               while (true) {
 
                   // 监测是否有新的连接，这里的1指的是阻塞的时间为 1ms
 
                   if (serverSelector.select(1) &gt; 0) {
 
                       Set&lt;SelectionKey&gt; set = serverSelector.selectedKeys();
 
                       Iterator&lt;SelectionKey&gt; keyIterator = set.iterator();
 
 
 
                       while (keyIterator.hasNext()) {
 
                           SelectionKey key = keyIterator.next();
 
 
 
                           if (key.isAcceptable()) {
 
                               try {
 
                                   // (1)
 
                                   // 每来一个新连接，不需要创建一个线程，而是直接注册到clientSelector
 
                                   SocketChannel clientChannel = ((ServerSocketChannel) key.channel()).accept();
 
                                   clientChannel.configureBlocking(false);
 
                                   clientChannel.register(clientSelector, SelectionKey.OP_READ);
 
                               } finally {
 
                                   keyIterator.remove();
 
                               }
 
                           }
 
 
 
                       }
 
                   }
 
               }
 
           } catch (IOException ignored) {
 
           }
 
       }).start();
 
       new Thread(() -&gt; {
 
           try {
 
               while (true) {
 
                   // (2) 批量轮询是否有哪些连接有数据可读，这里的1指的是阻塞的时间为 1ms
 
                   if (clientSelector.select(1) &gt; 0) {
 
                       Set&lt;SelectionKey&gt; set = clientSelector.selectedKeys();
 
                       Iterator&lt;SelectionKey&gt; keyIterator = set.iterator();
 
 
 
                       while (keyIterator.hasNext()) {
 
                           SelectionKey key = keyIterator.next();
 
 
 
                           if (key.isReadable()) {
 
                               try {
 
                                   SocketChannel clientChannel = (SocketChannel) key.channel();
 
                                   ByteBuffer byteBuffer = ByteBuffer.allocate(1024);
 
                                   // (3) 面向 Buffer
 
                                   clientChannel.read(byteBuffer);
 
                                   byteBuffer.flip();
 
                                   System.out.println(
 
                                           Charset.defaultCharset().newDecoder().decode(byteBuffer).toString());
 
                               } finally {
 
                                   keyIterator.remove();
 
                                   key.interestOps(SelectionKey.OP_READ);
 
                               }
 
                           }
 
 
 
                       }
 
                   }
 
               }
 
           } catch (IOException ignored) {
 
           }
 
       }).start();
 
 
 
   }
 
}
</code></pre>
<p>为什么大家都不愿意用 JDK 原生 NIO 进行开发呢？从上面的代码中大家都可以看出来，是真的难用！除了编程复杂、编程模型难之外，它还有以下让人诟病的问题：</p>
<pre><code>JDK 的 NIO 底层由 epoll 实现，该实现饱受诟病的空轮询 bug 会导致 cpu 飙升 100%

项目庞大之后，自行实现的 NIO 很容易出现各类 bug，维护成本较高，上面这一坨代码我都不能保证没有 bug
</code></pre>
<p>Netty 的出现很大程度上改善了 JDK 原生 NIO 所存在的一些让人难以忍受的问题。<br>
3. AIO (Asynchronous I/O)</p>
<p>AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。</p>
<p>AIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。（除了 AIO 其他的 IO 类型都是同步的，这一点可以从底层IO线程模型解释，推荐一篇文章：《漫话：如何给女朋友解释什么是Linux的五种IO模型？》 ）</p>
<p>查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。<br>
参考</p>
<pre><code>《Netty 权威指南》第二版

https://zhuanlan.zhihu.com/p/23488863 (美团技术团队)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[集合线程安全问题]]></title>
        <id>https://esinew.github.io/post/ji-he-xian-cheng-an-quan-wen-ti/</id>
        <link href="https://esinew.github.io/post/ji-he-xian-cheng-an-quan-wen-ti/">
        </link>
        <updated>2020-07-06T16:49:30.000Z</updated>
        <content type="html"><![CDATA[<p><strong>集合线程安全问题</strong></p>
<figure data-type="image" tabindex="1"><img src="https://esinew.github.io//post-images/1594054356639.png" alt="" loading="lazy"></figure>
<p>List用Vector或者加锁：</p>
<pre><code>Collection.synchronizedList(new ArrayList&lt;&gt;());
</code></pre>
<pre><code>Collections.synchronizedSet(new HashSet&lt;&gt;());
</code></pre>
<pre><code>Collections.synchronizedMap(new HashMap&lt;&gt;());
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[索引]]></title>
        <id>https://esinew.github.io/post/suo-yin/</id>
        <link href="https://esinew.github.io/post/suo-yin/">
        </link>
        <updated>2020-07-06T10:46:36.000Z</updated>
        <content type="html"><![CDATA[<p><strong>索引基础</strong></p>
<p>索引：排好序的快速查找数据结构；<br>
优点：提高数据检索的效率，降低数据排序的成本；<br>
缺点：会降低更新表的速度；</p>
<p>单值索引：一个索引只包含单个列，一个表可以由多个单值索引；<br>
唯一索引：索引列的值必须唯一，允许有空值；<br>
复合索引：即一个索引包含多个列；</p>
<p>索引结构：<br>
BTree索引，Hash索引，full-text全文索引，R-Tree索引；</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[BIO,NIO,AIO整理]]></title>
        <id>https://esinew.github.io/post/bionioaio-zheng-li/</id>
        <link href="https://esinew.github.io/post/bionioaio-zheng-li/">
        </link>
        <updated>2020-07-03T15:29:27.000Z</updated>
        <content type="html"><![CDATA[<p>以银行取款为例：</p>
<pre><code>同步 ： 自己亲自出马持银行卡到银行取钱（使用同步IO时，Java自己处理IO读写）。

异步 ： 委托一小弟拿银行卡到银行取钱，然后给你（使用异步IO时，Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS(银行卡和密码)，OS需要支持异步IO操作API）。

阻塞 ： ATM排队取款，你只能等待（使用阻塞IO时，Java调用会一直阻塞到读写完成才返回）。

非阻塞 ： 柜台取款，取个号，然后坐在椅子上做其它事，等号广播会通知你办理，没到号你就不能去，你可以不断问大堂经理排到了没有，大堂经理如果说还没到你就不能去（使用非阻塞IO时，如果不能读写Java调用会马上返回，当IO事件分发器会通知可读写时再继续进行读写，不断循环直到读写完成）。
</code></pre>
<p>Java对BIO、NIO、AIO的支持：</p>
<pre><code>Java BIO (blocking I/O)： 同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。

Java NIO (non-blocking I/O)： 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。

Java AIO(NIO.2) (Asynchronous I/O) ： 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理，
</code></pre>
<p>BIO、NIO、AIO适用场景分析:</p>
<pre><code>BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。

NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。

AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[http1.1和http2的比较]]></title>
        <id>https://esinew.github.io/post/http11-he-http2-de-bi-jiao/</id>
        <link href="https://esinew.github.io/post/http11-he-http2-de-bi-jiao/">
        </link>
        <updated>2020-06-29T17:13:05.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://esinew.github.io//post-images/1593849130260.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[斐波那契算法及其改进]]></title>
        <id>https://esinew.github.io/post/fei-bo-na-qi-suan-fa-ji-qi-gai-jin/</id>
        <link href="https://esinew.github.io/post/fei-bo-na-qi-suan-fa-ji-qi-gai-jin/">
        </link>
        <updated>2020-06-29T17:09:44.000Z</updated>
        <content type="html"><![CDATA[<p>斐波那契算法</p>
<pre><code>Fibonacci(int n){

if(n==1||n==2){

return 1;

}

return Fibonacci(n-1)+Fibonacci(n-2)；

}
</code></pre>
<p>改进（解决溢出问题、性能问题）</p>
<pre><code>private static readonly Dictionary&lt;int,BigInteger&gt; _cach = new Dictionary&lt;int,BigInteger&gt;();
public static BigIneger Fibonacci(int n){
	if(n &lt; = 2){
	return 1;
	}
	if(_cach.TryGetValue(n,out BigInteger result)){
	return result;
	}
	result = Fibonacci(n-1)+Fibonacci(n-2);
	_cach.Add(n,result);
	return result;
	
}
</code></pre>
<p>{f(n), f(n-1), f(n-1), f(n-2)} ={1, 1, 1,0}n-1</p>
<p>(注：{f(n+1), f(n), f(n), f(n-1)}表示一个矩阵。在矩阵中第一行第一列是f(n+1)，第一行第二列是f(n)，第二行第一列是f(n)，第二行第二列是f(n-1)。，如果还不懂的话，再去看一下线性代数)</p>
<p>有了这个公式，要求得f(n)，我们只需要求得矩阵{1, 1, 1,0}的n-1次方，因为矩阵{1, 1, 1,0}的n-1次方的结果的第一行第一列就是f(n)。这个数学公式用数学归纳法不难证明。感兴趣的朋友不妨自己证明一下。<br>
现在的问题转换为求矩阵{1, 1, 1, 0}的乘方。如果简单第从0开始循环，n次方将需要n次运算，并不比前面的方法要快。但我们可以考虑乘方的如下性质：</p>
<p>​    / an/2<em>an/2           n为偶数时<br>
an=<br>
​    \ a(n-1)/2</em>a(n-1)/2      n为奇数时</p>
<p>要求得n次方，我们先求得n/2次方，再把n/2的结果平方一下。如果把求n次方的问题看成一个大问题，把求n/2看成一个较小的问题。这种把大问题分解成一个或多个小问题的思路我们称之为分治法。这样求n次方就只需要logn次运算了。</p>
<p>实现这种方式时，首先需要定义一个2×2的矩阵，并且定义好矩阵的乘法以及乘方运算。当这些运算定义好了之后，剩下的事情就变得非常简单。完整的实现代码如下所示。</p>
<pre><code>struct Matrix2By2
{
      Matrix2By2
      (
            long long m00 = 0, 
            long long m01 = 0, 
            long long m10 = 0, 
            long long m11 = 0
      )
      :m_00(m00), m_01(m01), m_10(m10), m_11(m11) 
      {
      }

      long long m_00;
      long long m_01;
      long long m_10;
      long long m_11;
};

</code></pre>
<pre><code>///////////////////////////////////////////////////////////////////////
// Multiply two matrices
// Input: matrix1 - the first matrix
//        matrix2 - the second matrix
//Output: the production of two matrices
///////////////////////////////////////////////////////////////////////
Matrix2By2 MatrixMultiply
(
      const Matrix2By2&amp; matrix1, 
      const Matrix2By2&amp; matrix2
)
{
      return Matrix2By2(
            matrix1.m_00 * matrix2.m_00 + matrix1.m_01 * matrix2.m_10,
            matrix1.m_00 * matrix2.m_01 + matrix1.m_01 * matrix2.m_11,
            matrix1.m_10 * matrix2.m_00 + matrix1.m_11 * matrix2.m_10,
            matrix1.m_10 * matrix2.m_01 + matrix1.m_11 * matrix2.m_11);
}

///////////////////////////////////////////////////////////////////////
// The nth power of matrix 
// 1  1
// 1  0
///////////////////////////////////////////////////////////////////////
Matrix2By2 MatrixPower(unsigned int n)
{
      assert(n &gt; 0);

      Matrix2By2 matrix;
      if(n == 1)
      {
            matrix = Matrix2By2(1, 1, 1, 0);
      }
      else if(n % 2 == 0)
      {
            matrix = MatrixPower(n / 2);
            matrix = MatrixMultiply(matrix, matrix);
      }
      else if(n % 2 == 1)
      {
            matrix = MatrixPower((n - 1) / 2);
            matrix = MatrixMultiply(matrix, matrix);
            matrix = MatrixMultiply(matrix, Matrix2By2(1, 1, 1, 0));
      }

      return matrix;
}

///////////////////////////////////////////////////////////////////////
// Calculate the nth item of Fibonacci Series using devide and conquer
///////////////////////////////////////////////////////////////////////
long long Fibonacci_Solution3(unsigned int n)
{
      int result[2] = {0, 1};
      if(n &lt; 2)
            return result[n];

      Matrix2By2 PowerNMinus2 = MatrixPower(n - 1);
      return PowerNMinus2.m_00;
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mybiatis使用MybatisCodeHelperPro插件快速开发]]></title>
        <id>https://esinew.github.io/post/mybiatis-shi-yong-mybatiscodehelperpro-cha-jian-kuai-su-kai-fa/</id>
        <link href="https://esinew.github.io/post/mybiatis-shi-yong-mybatiscodehelperpro-cha-jian-kuai-su-kai-fa/">
        </link>
        <updated>2020-06-28T18:14:31.000Z</updated>
        <content type="html"><![CDATA[<p>（转载自 简书  葛俊_0f97）<br>
如何达到最快的效率 下面是我的开发流程</p>
<p>java类生成crud 不再推荐使用 各种功能没有数据库生成crud 方便 数据库生成crud 在表字段 添加减少字段 合并代码也做得更好</p>
<p>数据库的话 首先要建表 直接写建表语句比较麻烦 我们可以通过java类生成建表语句来生成好</p>
<p>我们先写一个超级简单的java类 啥也不需要加 private也不需要 这个类只是用来生成建表语句</p>
<figure data-type="image" tabindex="1"><img src="https://esinew.github.io//post-images/1593368287814.gif" alt="" loading="lazy"></figure>
<p>mybatis快速开发.gif</p>
<p>生成好了建表语句后 到数据库执行下 然后从数据库来生成crud代码</p>
<p>(使用IDEA高级版的用户直接到IDEA高级版的数据库执行就行)</p>
<p>这时就可以选择各种配置了</p>
<p>在数据库添加 减少字段后 到数据库 重新生成下就好了</p>
<p>当我们数据库用的tinyInt 或者 smallInt这种 生成java类型 是 byte 和 short 两种类型</p>
<p>在java代码里面操作 byte 和 short 类型 比较麻烦 经常需要 强制转换 这是可以配置下 设置 使用Integer 来替代byte和short</p>
<p><img src="https://esinew.github.io//post-images/1593368312200.png" alt="" loading="lazy"><br>
useIntegerInsteadOfByteAndShort.png</p>
<p>在数据库生成crud时 部分用户可能会勾选 生成example 这个选项</p>
<p>我建议使用 方法名生成sql 来替代生成example这个</p>
<p>首先可以避免生成一大堆的example文件 xml中的example代码看起来也很恶心</p>
<p>写方法名生成sql 的效率也比写example来得快</p>
<p>看xml也很清楚 到底进行了啥操作</p>
<p>另外2.5版本 将支持 定制sql 数据库生成crud中 默认生成的那些语句 比如deleteByPrimaryKey 有不需要的可以一开始就给干掉</p>
<p>如果之后要的话 可以从数据库重新来生成 比如batchInsert 这种 只有当前表需要的时候才来生成</p>
<p>另外我也不推荐 mapper接口做继承 现在代码都是自动生成的，mapper做继承仅能减少一些代码量，没有看到什么其他的效率提升。搞了继承后 看mapper接口 对应的xml 也变得比较麻烦 哪些方法要放到继承里面也比较难定义，有可能某些接口继承的方法根本用不到, 我的建议是每个接口 只生成自己需要的xml方法， 比如batchInsert这个，有个表需要 有的表并不需要。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql(InnoDB)索引的原理]]></title>
        <id>https://esinew.github.io/post/mysqlinnodbsuo-yin-de-yuan-li/</id>
        <link href="https://esinew.github.io/post/mysqlinnodbsuo-yin-de-yuan-li/">
        </link>
        <updated>2020-06-24T02:00:13.000Z</updated>
        <content type="html"><![CDATA[<p>(转载作者：孤独烟 出处： http://rjzheng.cnblogs.com/)</p>
<h2 id="引言">引言</h2>
<p>回想四年前，我在学习mysql的索引这块的时候，老师在讲索引的时候，是像下面这么说的</p>
<blockquote>
<p><strong>索引就像一本书的目录。而当用户通过索引查找数据时，就好比用户通过目录查询某章节的某个知识点。这样就帮助用户有效地提高了查找速度。所以，使用索引可以有效地提高数据库系统的整体性能。</strong></p>
</blockquote>
<p>嗯，这么说其实也对。但是呢，大家看完这种说法，其实可能还是觉得太抽象了！因此呢，我还想再深入的细说一下，所以就有了此文！<br>
需要说明的是，我说的内容只在Mysql的Innodb引擎中是成立的。在Sql Server、oracle、Mysql的Mysiam引擎中的正确性，不一定成立！<br>
OK，废话不多说，开始啰嗦!</p>
<h2 id="正文">正文</h2>
<h3 id="索引的科普">索引的科普</h3>
<p>先引进聚簇索引和非聚簇索引的概念！<br>
我们平时在使用的Mysql中，使用下述语句</p>
<pre><code>CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name
    [USING index_type]
    ON tbl_name (index_col_name,...)
 
index_col_name:
    col_name [(length)] [ASC | DESC]
</code></pre>
<p>创建的索引，如复合索引、前缀索引、唯一索引，都是属于非聚簇索引，在有的书籍中，又将其称为辅助索引(secondary index)。在后文中，我们称其为非聚簇索引，其数据结构为B+树。</p>
<p>那么，这个聚簇索引，在Mysql中是没有语句来另外生成的。在Innodb中，Mysql中的数据是按照主键的顺序来存放的。那么聚簇索引就是按照每张表的主键来构造一颗B+树，叶子节点存放的就是整张表的行数据。由于表里的数据只能按照一颗B+树排序，因此一张表只能有一个聚簇索引。</p>
<p>在Innodb中，聚簇索引默认就是主键索引。<br>
这个时候，机智的读者，应该要问我</p>
<blockquote>
<p><strong>如果我的表没建主键呢？</strong></p>
</blockquote>
<p>回答是，如果没有主键，则按照下列规则来建聚簇索引</p>
<ul>
<li>没有主键时，会用一个唯一且不为空的索引列做为主键，成为此表的聚簇索引</li>
<li>如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。</li>
</ul>
<p><code>ps</code>:大家还记得，自增主键和uuid作为主键的区别么？由于主键使用了聚簇索引，如果主键是自增id，，那么对应的数据一定也是相邻地存放在磁盘上的，写入性能比较高。如果是uuid的形式，频繁的插入会使innodb频繁地移动磁盘块，写入性能就比较低了。</p>
<h3 id="索引原理介绍">索引原理介绍</h3>
<p>先来一张带主键的表，如下所示，pId是主键</p>
<table>
<thead>
<tr>
<th>pId</th>
<th>name</th>
<th>birthday</th>
</tr>
</thead>
<tbody>
<tr>
<td>5</td>
<td>zhangsan</td>
<td>2016-10-02</td>
</tr>
<tr>
<td>8</td>
<td>lisi</td>
<td>2015-10-04</td>
</tr>
<tr>
<td>11</td>
<td>wangwu</td>
<td>2016-09-02</td>
</tr>
<tr>
<td>13</td>
<td>zhaoliu</td>
<td>2015-10-07</td>
</tr>
</tbody>
</table>
<p>画出该表的结构图如下<br>
<img src="https://www.cnblogs.com/images/cnblogs_com/rjzheng/1281019/o_index01.png" alt="image" loading="lazy"></p>
<p>如上图所示，分为上下两个部分，上半部分是由主键形成的B+树，下半部分就是磁盘上真实的数据！那么，当我们， 执行下面的语句</p>
<pre><code>select * from table where pId='11'
</code></pre>
<p>那么，执行过程如下<br>
<img src="https://www.cnblogs.com/images/cnblogs_com/rjzheng/1281019/o_index02.png" alt="image" loading="lazy"><br>
如上图所示，从根开始，经过3次查找，就可以找到真实数据。如果不使用索引，那就要在磁盘上，进行逐行扫描，直到找到数据位置。显然，使用索引速度会快。但是在写入数据的时候，需要维护这颗B+树的结构，因此写入性能会下降！<br>
OK，接下来引入非聚簇索引!我们执行下面的语句</p>
<pre><code>create index index_name on table(name);
</code></pre>
<p>此时结构图如下所示<br>
<img src="https://www.cnblogs.com/images/cnblogs_com/rjzheng/1281019/o_index04.png" alt="image" loading="lazy"><br>
大家注意看，会根据你的索引字段生成一颗新的B+树。因此， 我们每加一个索引，就会增加表的体积， 占用磁盘存储空间。然而，<strong>注意看叶子节点</strong>，非聚簇索引的叶子节点并不是真实数据，它的叶子节点依然是索引节点，存放的是该索引字段的值以及对应的主键索引(聚簇索引)。<br>
如果我们执行下列语句</p>
<pre><code>select * from table where name='lisi'
</code></pre>
<p>此时结构图如下所示<br>
<img src="https://www.cnblogs.com/images/cnblogs_com/rjzheng/1281019/o_index05.png" alt="image" loading="lazy"><br>
通过上图红线可以看出，先从非聚簇索引树开始查找，然后找到聚簇索引后。根据聚簇索引，在聚簇索引的B+树上，找到完整的数据！<br>
那</p>
<blockquote>
<p><strong>什么情况不去聚簇索引树上查询呢？</strong></p>
</blockquote>
<p>还记得我们的非聚簇索引树上存着该索引字段的值么。如果，此时我们执行下面的语句</p>
<pre><code>select name from table where name='lisi'
</code></pre>
<p>此时结构图如下<br>
<img src="https://www.cnblogs.com/images/cnblogs_com/rjzheng/1281019/o_index06.png" alt="image" loading="lazy"><br>
如上图红线所示，如果在非聚簇索引树上找到了想要的值，就不会去聚簇索引树上查询。还记得，博主在<a href="https://www.cnblogs.com/rjzheng/p/9902911.html">《select的正确姿势》</a>提到的索引问题么：</p>
<blockquote>
<p><strong>当执行select col from table where col = ?，col上有索引的时候，效率比执行select * from table where col = ? 速度快好几倍！</strong></p>
</blockquote>
<p>看完上面的图，你应该对这句话有更深层的理解了。</p>
<p>那么这个时候，我们执行了下述语句，又会发生什么呢？</p>
<pre><code>create index index_birthday on table(birthday);
</code></pre>
<p>此时结构图如下<br>
<img src="https://www.cnblogs.com/images/cnblogs_com/rjzheng/1281019/o_index07.png" alt="image" loading="lazy"><br>
看到了么，多加一个索引，就会多生成一颗非聚簇索引树。因此，很多文章才说，索引不能乱加。因为，有几个索引，就有几颗非聚簇索引树！你在做插入操作的时候，需要同时维护这几颗树的变化！因此，如果索引太多，插入性能就会下降!</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql事务隔离级别及MVCC]]></title>
        <id>https://esinew.github.io/post/mysql-shi-wu-ge-chi-ji-bie-ji-mvcc/</id>
        <link href="https://esinew.github.io/post/mysql-shi-wu-ge-chi-ji-bie-ji-mvcc/">
        </link>
        <updated>2020-06-24T01:43:32.000Z</updated>
        <summary type="html"><![CDATA[<p>MySQL定义了4类隔离级别，包括一些具体规则，用来限定事物内外的哪些改变时可见的，哪些改变时不可见的，低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。</p>
<p><strong>第一类：</strong> Read Uncommitted(读取未提交的内容)事务A/事务B    在该隔离级别，所有事物都可以看到其他未提交事务的执行结果，本隔离级别很少用于实际应用，因为他的性能页不比其他级别好多少，读取未提交的数据，也被称之为脏读（Dirty Read）。</p>
<p><strong>第二类：</strong> Read Committed(读取提交内容)    这是大多数数据库系统的默认隔离级别（但不是mysql默认的），他满足了隔离的简单定义：一个事物在提交之前对其他事物是不可见的，这种隔离级别也支持所谓的不可重复读取（Nonerepeatable Read）,因为同一事务的其他实例在该实例处理其他期间可能会有新的commit，所以同一select可能返回不同结果。</p>
<p><strong>第三类：</strong> Repeatable Read(可复读)    这是mysql默认的隔离级别，他确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，不过理论上，这会导致另一个棘手的问题，幻读（Phantom Read），简单的说，幻读指当用户读取某一范围的数据行时，另一个事物又在该范围内插入了新行，当用户再读取该范围内的数据时，会发现有新的&quot;幻影&quot;行，Innodb和Falcon存储引擎通过多版本并发控制（MVCC）机制解决了该问题。</p>
<p><strong>第四类：</strong> Serializerable(可串行化)    这是最高的隔离级别，他通过强制事物排序，使之不可能相互冲突，从而解决了幻读问题，简言之，它是在每个读的数据行上加共享锁，在这个级别，可能导致大量的超时现象和锁竞争。</p>
<p>脏读：    某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个事务RollBack了操作，则后面的事物所读去的数据就是不正确的。<br>
幻读：    在一个事务的两次查询中数据不一致，例如有一个事务查询了几列数据，而另一个事务却在此时插入了新的数据，先前的事务在接下来的查询中，就会发现有几列数据是他先前所没有的。（数据条数不同）<br>
不可重复读：    在一个事物的两次查询中数据不一致，这可能是两次查询过程中间插入了一个事物更新的原有的数据。（同一条数据）<br>
以上四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。<br>
隔离级别 脏读 不可重复读 幻读读取未提交内容 v v v读取已提交内容 x v v 可重复读 x x v 可串行化 x x x<br>
修改MySQL隔离级别：</p>
<p><em>sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf</em></p>
<p><img src="https://esinew.github.io//post-images/1592963778005.jpg" alt="" loading="lazy"><br>
修改完成后重启mysql，使其生效：</p>
<p><u><em>sudo service mysql restart</em></u></p>
<p><strong>Django提供了一个API来控制数据库事务</strong></p>
<p><u><em>atomic(using=None, savepoint=True)</em></u></p>
<p>原子性： 是由mysql的事物操作来界定的，atomic允许我们在执行代码块时，在数据库层面提供原子性保证，如果代码块成功完成，相应的变化会被提交到数据库进行commit，否则会进行rollback。</p>
<p>atomic可以嵌套，在下面的例子里，使用while语句，当一个内部块完成后，如果某个异常在外部块被抛出，内部块上的操作仍然可以回滚（前提是外部块也被atomic装饰过）</p>
<p><em>atomic被用作装饰器</em><br>
<u><em>from django.db import transaction</em></u></p>
<p><u>***@transaction.atomic***</u></p>
<p><u><em>def viewfunc(request):</em></u></p>
<p><u><em>do_stuff()</em></u></p>
<p>创建保存点</p>
<p><u><em>savepoint()</em></u></p>
<p>提交保存点</p>
<p><u><em>savepoint_commit</em>()</u></p>
<p>回滚保存点</p>
<p><u><em>savepoint_rollback</em>()</u></p>
<p>订单并发处理悲观锁乐观锁在冲突比较少的时候采用乐观锁，减少不需要加锁释放锁的开销，可以提高性能。<br>
在冲突比较多的时候采用悲观锁，减少重复尝试次数，乐观锁重复操作的代价比较大。</p>
<p><strong>MySQL的MVCC及实现原理</strong></p>
<p>首先声明，MySQL的测试环境是5.7</p>
<p>前提概要</p>
<p><em><u>什么是MVCC?</u></em></p>
<p>MVCCMVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读</p>
<p><em><u>什么是当前读和快照读？</u></em></p>
<p>在学习MVCC多版本并发控制之前，我们必须先了解一下，什么是MySQL InnoDB下的当前读和快照读?</p>
<p>当前读像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，</p>
<p><em><u>为什么叫当前读？</u></em></p>
<p>就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁快照读像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。</p>
<p>说白了MVCC就是为了实现读-写冲突不加锁，而这个读指的就是快照读, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现当前读，快照读和MVCC的关系准确的说，MVCC多版本并发控制指的是 “维持一个数据的多个版本，使得读写操作没有冲突” 这么一个概念。仅仅是一个理想概念而在MySQL中，实现这么一个MVCC理想概念，我们就需要MySQL提供具体的功能去实现它，而快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。</p>
<p>而相对而言，当前读就是悲观锁的具体功能实现，要说的再细致一些，快照读本身也是一个抽象概念，再深入研究。MVCC模型在MySQL中的具体实现则是由 3个隐式字段，undo日志 ，Read View 等去完成的，具体可以看下面的MVCC实现原理</p>
<p><em><u>MVCC能解决什么问题，好处是？</u></em></p>
<p>数据库并发场景有三种，分别为：</p>
<p>读-读：不存在任何问题，也不需要并发控制</p>
<p>读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，</p>
<p>幻读，不可重复读写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失</p>
<p><em><u>MVCC带来的好处是？</u></em></p>
<p>多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以MVCC可以为数据库解决以下问题在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题小结一下总之，MVCC就是因为大牛们，不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题而提出的解决方案，所以在数据库中有了MVCC，所以我们可以形成两个组合：</p>
<p>MVCC + 悲观锁MVCC解决读写冲突，悲观锁解决写写冲突</p>
<p>MVCC + 乐观锁MVCC解决读写冲突，乐观锁解决写写冲突</p>
<p>这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题*<u>MYSQL 事务日志</u>*</p>
<p>事务日志可以帮助提高事务的效率。使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。事务日志持久以后，内存中被修改的数据在后台可以慢慢地刷回到磁盘。目前大多数存储引擎都是这样实现的，我们通常称之为预写式日志（Write-Ahead Logging），修改数据需要写两次磁盘。 如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。</p>
<p>MySQL Innodb中跟数据持久性、一致性有关的日志，有以下几种：</p>
<p>**1.**Bin Log:是mysql服务层产生的日志，常用来进行数据恢复、数据库复制，常见的mysql主从架构，就是采用slave同步master的binlog实现的Redo Log:记录了数据操作在物理层面的修改，mysql中使用了大量缓存，修改操作时会直接修改内存，而不是立刻修改磁盘，事务进行中时会不断的产生redo log，在事务提交时进行一次flush操作，保存到磁盘中。当数据库或主机失效重启时，会根据redo log进行数据的恢复，如果redo log中有事务提交，则进行事务提交修改数据。</p>
<p>**<u>2.</u>**Undo Log: 除了记录redo log外，当进行数据修改时还会记录undo log，undo log用于数据的撤回操作，它记录了修改的反向操作，比如，插入对应删除，修改对应修改为原来的数据，通过undo log可以实现事务回滚，并且可以根据undo log回溯到某个特定的版本的数据，实现MVCC</p>
<p><u><em>MVCC的实现原理</em></u></p>
<p>MVCC的目的就是多版本并发控制，在数据库中的实现，就是为了解决读写冲突，它的实现原理主要是依赖记录中的 3个隐式字段，undo日志 ，Read View 来实现的。所以我们先来看看这个三个point的概念隐式字段每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID等字段</p>
<p>DB_TRX_ID 6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务IDDB_ROLL_PTR 7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）DB_ROW_ID 6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了<br>
如上图，DB_ROW_ID是数据库默认为该行记录生成的唯一隐式主键，DB_TRX_ID是当前操作该记录的事务ID,而DB_ROLL_PTR是一个回滚指针，用于配合undo日志，指向上一个旧版本undo日志</p>
<p>undo log主要分为两种：</p>
<p>insert undo log代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃</p>
<p>update undo log事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除purge</p>
<p>从前面的分析可以看出，为了实现InnoDB的MVCC机制，更新或者删除操作都只是设置一下老记录的deleted_bit，并不真正将过时的记录删除。为了节省磁盘空间，InnoDB有专门的purge线程来清理deleted_bit为true的记录。为了不影响MVCC的正常工作，purge线程自己也维护了一个read view（这个read view相当于系统中最老活跃事务的read view）;如果某个记录的deleted_bit为true，并且DB_TRX_ID相对于purge线程的read view可见即当前记录没有相关活跃事务在操作时，那么这条记录一定是可以被安全清除的。对MVCC有帮助的实质是update undo log ，undo log实际上就是存在rollback segment中旧记录链，它的执行流程如下：</p>
<p>一、 比如一个有个事务插入persion表插入了一条新记录，记录如下，name为Jerry, age为24岁，隐式主键是1，事务ID和回滚指针，我们假设为NULL<br>
二、 现在来了一个事务1对该记录的name做出了修改，改为Tom在事务1修改该行(记录)数据时，数据库会先对该行加排他锁然后把该行数据拷贝到undo log中，作为旧记录，既在undo log中有当前行的拷贝副本拷贝完毕后，修改该行name为Tom，并且修改隐藏字段的事务ID为当前事务1的ID, 我们默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，既表示我的上一个版本就是它事务提交后，释放锁</p>
<p>三、 又来了个事务2修改person表的同一个记录，将age修改为30岁在事务2修改该行数据时，数据库也先为该行加锁然后把该行数据拷贝到undo log中，作为旧记录，发现该行记录已经有undo log了，那么最新的旧数据作为链表的表头，插在该行记录的undo log最前面修改该行age为30岁，并且修改隐藏字段的事务ID为当前事务2的ID, 那就是2，回滚指针指向刚刚拷贝到undo log的副本记录事务提交，释放锁<br>
从上面，我们就可以看出，不同事务或者相同事务的对同一记录的修改，会导致该记录的undo log成为一条记录版本线性表，既链表，undo log的链首就是最新的旧记录，链尾就是最早的旧记录（当然就像之前说的该undo log的节点可能是会purge线程清除掉，向图中的第一条insert undo log，其实在事务提交之后可能就被删除丢失了，不过这里为了演示，所以还放在这里）Read View(读视图)</p>
<p><em><u>什么是Read View?</u></em></p>
<p>什么是Read View，说白了Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大)。所以我们知道 Read View主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。</p>
<p>Read View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果DB_TRX_ID跟Read View的属性做了某些比较，不符合可见性，那就通过DB_ROLL_PTR回滚指针去取出Undo Log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的DB_TRX_ID, 那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新老版本那么这个判断条件是什么呢？</p>
<p>如上，它是一段MySQL判断可见性的一段源码，即changes_visible方法（不完全哈，但能看出大致逻辑），该方法展示了我们拿DB_TRX_ID去跟Read View某些属性进行怎么样的比较在展示之前，我先简化一下Read View，我们可以把Read View简单的理解成有三个全局属性。</p>
<p>trx_list（名字我随便取的）一个数值列表，用来维护Read View生成时刻系统正活跃的事务IDup_limit_id记录trx_list列表中事务ID最小的IDlow_limit_idReadView生成时刻系统尚未分配的下一个事务ID，也就是目前已出现过的事务ID的最大值+1，首先比较DB_TRX_ID &lt; up_limit_id, 如果小于，则当前事务能看到DB_TRX_ID 所在的记录，如果大于等于进入下一个判断。接下来判断 DB_TRX_ID 大于等于 low_limit_id , 如果大于等于则代表DB_TRX_ID 所在的记录在Read View生成后才出现的，那对当前事务肯定不可见，如果小于则进入下一个判断判断DB_TRX_ID 是否在活跃事务之中，trx_list.contains(DB_TRX_ID)，如果在，则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是看不见的；如果不在，则说明，你这个事务在Read View生成之前就已经Commit了，你修改的结果，我当前事务是能看见的。</p>
<p>整体流程</p>
<p>我们在了解了隐式字段，undo log， 以及Read View的概念之后，就可以来看看MVCC实现的整体流程是怎么样了整体的流程是怎么样的呢？我们可以模拟一下：</p>
<p>当事务2对某行数据执行了快照读，数据库为该行数据生成一个Read View读视图，假设当前事务ID为2，此时还有事务1和事务3在活跃中，事务4在事务2快照读前一刻提交更新了，所以Read View记录了系统当前活跃事务1，3的ID，维护在一个列表上，假设我们称为trx_list。</p>
<p>事务1事务2事务3事务4事务开始事务开始事务开始事务开始………修改且已提交进行中快照读进行中………</p>
<p>Read View不仅仅会通过一个列表trx_list来维护事务2执行快照读那刻系统正活跃的事务ID，还会有两个属性up_limit_id（记录trx_list列表中事务ID最小的ID），low_limit_id(记录trx_list列表中事务ID最大的ID，也有人说快照读那刻系统尚未分配的下一个事务ID也就是目前已出现过的事务ID的最大值+1，我更倾向于后者 ) ；所以在这里例子中up_limit_id就是1，low_limit_id就是4 + 1 = 5，trx_list集合的值是1,3，Read View如下图：</p>
<p>我们的例子中，只有事务4修改过该行记录，并在事务2执行快照读前，就提交了事务，所以当前该行当前数据的undo log如下图所示；我们的事务2在快照读该行记录的时候，就会拿该行记录的DB_TRX_ID去跟up_limit_id,low_limit_id和活跃事务ID列表(trx_list)进行比较，判断当前事务2能看到该记录的版本是哪个。<br>
所以先拿该记录DB_TRX_ID字段记录的事务ID 4去跟Read View的的up_limit_id比较，看4是否小于up_limit_id(1)，所以不符合条件，继续判断 4 是否大于等于 low_limit_id(5)，也不符合条件，最后判断4是否处于trx_list中的活跃事务, 最后发现事务ID为4的事务不在当前活跃事务列表中, 符合可见性条件，所以事务4修改后提交的最新结果对事务2快照读时是可见的，所以事务2能读到的最新数据记录是事务4所提交的版本，而事务4提交的版本也是全局角度上最新的版本。</p>
<p>也正是Read View生成时机的不同，从而造成RC,RR级别下快照读的结果的不同。</p>
<p><strong><u><em>MVCC相关问题</em></u></strong></p>
<p><u><em>RR是如何在RC级的基础上解决不可重复读的？</em></u></p>
<p>当前读和快照读在RR级别下的区别：</p>
<p>表1:事务A事务B开启事务开启事务快照读(无影响)查询金额为500快照读查询金额为500更新金额为400提交事务select 快照读金额为500select lock in share mode当前读金额为400在上表的顺序下，事务B的在事务A提交修改后的快照读是旧版本数据，而当前读是实时新数据400。</p>
<p>表2:事务A事务B开启事务开启事务快照读（无影响）查询金额为500更新金额为400提交事务select 快照读金额为400select lock in share mode当前读金额为400。</p>
<p>而在表2这里的顺序中，事务B在事务A提交后的快照读和当前读都是实时的新数据400，这是为什么呢？这里与上表的唯一区别仅仅是表1的事务B在事务A修改金额前快照读过一次金额数据，而表2的事务B在事务A修改金额前没有进行过快照读。所以我们知道事务中快照读的结果是非常依赖该事务首次出现快照读的地方，即某个事务中首次出现快照读的地方非常关键，它有决定该事务后续快照读结果的能力，我们这里测试的是更新，同时删除和更新也是一样的，如果事务B的快照读是在事务A操作之后进行的，事务B的快照读也是能读取到最新的数据的。</p>
<p><em><u>RC,RR级别下的InnoDB快照读有什么不同？</u></em></p>
<p>正是Read View生成时机的不同，从而造成RC,RR级别下快照读的结果的不同。在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View, 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个Read View，所以对之后的修改不可见；即RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见。而在RC级别下的，事务中，每次快照读都会新生成一个快照和Read View, 这就是我们在RC级别下的事务中可以看到别的事务提交的更新的原因。</p>
<p><strong><u>MVCC原理：</u></strong></p>
<p>MVCC（ Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用READ COMMITTD、REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程。可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。 READ COMMITTD、 REPEATABLE READ这两个隔离级别的一个很大不同就是：生成ReadView的时机不同， READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。</p>
]]></summary>
        <content type="html"><![CDATA[<p>MySQL定义了4类隔离级别，包括一些具体规则，用来限定事物内外的哪些改变时可见的，哪些改变时不可见的，低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。</p>
<p><strong>第一类：</strong> Read Uncommitted(读取未提交的内容)事务A/事务B    在该隔离级别，所有事物都可以看到其他未提交事务的执行结果，本隔离级别很少用于实际应用，因为他的性能页不比其他级别好多少，读取未提交的数据，也被称之为脏读（Dirty Read）。</p>
<p><strong>第二类：</strong> Read Committed(读取提交内容)    这是大多数数据库系统的默认隔离级别（但不是mysql默认的），他满足了隔离的简单定义：一个事物在提交之前对其他事物是不可见的，这种隔离级别也支持所谓的不可重复读取（Nonerepeatable Read）,因为同一事务的其他实例在该实例处理其他期间可能会有新的commit，所以同一select可能返回不同结果。</p>
<p><strong>第三类：</strong> Repeatable Read(可复读)    这是mysql默认的隔离级别，他确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，不过理论上，这会导致另一个棘手的问题，幻读（Phantom Read），简单的说，幻读指当用户读取某一范围的数据行时，另一个事物又在该范围内插入了新行，当用户再读取该范围内的数据时，会发现有新的&quot;幻影&quot;行，Innodb和Falcon存储引擎通过多版本并发控制（MVCC）机制解决了该问题。</p>
<p><strong>第四类：</strong> Serializerable(可串行化)    这是最高的隔离级别，他通过强制事物排序，使之不可能相互冲突，从而解决了幻读问题，简言之，它是在每个读的数据行上加共享锁，在这个级别，可能导致大量的超时现象和锁竞争。</p>
<p>脏读：    某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个事务RollBack了操作，则后面的事物所读去的数据就是不正确的。<br>
幻读：    在一个事务的两次查询中数据不一致，例如有一个事务查询了几列数据，而另一个事务却在此时插入了新的数据，先前的事务在接下来的查询中，就会发现有几列数据是他先前所没有的。（数据条数不同）<br>
不可重复读：    在一个事物的两次查询中数据不一致，这可能是两次查询过程中间插入了一个事物更新的原有的数据。（同一条数据）<br>
以上四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。<br>
隔离级别 脏读 不可重复读 幻读读取未提交内容 v v v读取已提交内容 x v v 可重复读 x x v 可串行化 x x x<br>
修改MySQL隔离级别：</p>
<p><em>sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf</em></p>
<p><img src="https://esinew.github.io//post-images/1592963778005.jpg" alt="" loading="lazy"><br>
修改完成后重启mysql，使其生效：</p>
<p><u><em>sudo service mysql restart</em></u></p>
<p><strong>Django提供了一个API来控制数据库事务</strong></p>
<p><u><em>atomic(using=None, savepoint=True)</em></u></p>
<p>原子性： 是由mysql的事物操作来界定的，atomic允许我们在执行代码块时，在数据库层面提供原子性保证，如果代码块成功完成，相应的变化会被提交到数据库进行commit，否则会进行rollback。</p>
<p>atomic可以嵌套，在下面的例子里，使用while语句，当一个内部块完成后，如果某个异常在外部块被抛出，内部块上的操作仍然可以回滚（前提是外部块也被atomic装饰过）</p>
<p><em>atomic被用作装饰器</em><br>
<u><em>from django.db import transaction</em></u></p>
<p><u>***@transaction.atomic***</u></p>
<p><u><em>def viewfunc(request):</em></u></p>
<p><u><em>do_stuff()</em></u></p>
<p>创建保存点</p>
<p><u><em>savepoint()</em></u></p>
<p>提交保存点</p>
<p><u><em>savepoint_commit</em>()</u></p>
<p>回滚保存点</p>
<p><u><em>savepoint_rollback</em>()</u></p>
<p>订单并发处理悲观锁乐观锁在冲突比较少的时候采用乐观锁，减少不需要加锁释放锁的开销，可以提高性能。<br>
在冲突比较多的时候采用悲观锁，减少重复尝试次数，乐观锁重复操作的代价比较大。</p>
<p><strong>MySQL的MVCC及实现原理</strong></p>
<p>首先声明，MySQL的测试环境是5.7</p>
<p>前提概要</p>
<p><em><u>什么是MVCC?</u></em></p>
<p>MVCCMVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读</p>
<p><em><u>什么是当前读和快照读？</u></em></p>
<p>在学习MVCC多版本并发控制之前，我们必须先了解一下，什么是MySQL InnoDB下的当前读和快照读?</p>
<p>当前读像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，</p>
<p><em><u>为什么叫当前读？</u></em></p>
<p>就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁快照读像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。</p>
<p>说白了MVCC就是为了实现读-写冲突不加锁，而这个读指的就是快照读, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现当前读，快照读和MVCC的关系准确的说，MVCC多版本并发控制指的是 “维持一个数据的多个版本，使得读写操作没有冲突” 这么一个概念。仅仅是一个理想概念而在MySQL中，实现这么一个MVCC理想概念，我们就需要MySQL提供具体的功能去实现它，而快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。</p>
<p>而相对而言，当前读就是悲观锁的具体功能实现，要说的再细致一些，快照读本身也是一个抽象概念，再深入研究。MVCC模型在MySQL中的具体实现则是由 3个隐式字段，undo日志 ，Read View 等去完成的，具体可以看下面的MVCC实现原理</p>
<p><em><u>MVCC能解决什么问题，好处是？</u></em></p>
<p>数据库并发场景有三种，分别为：</p>
<p>读-读：不存在任何问题，也不需要并发控制</p>
<p>读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，</p>
<p>幻读，不可重复读写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失</p>
<p><em><u>MVCC带来的好处是？</u></em></p>
<p>多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以MVCC可以为数据库解决以下问题在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题小结一下总之，MVCC就是因为大牛们，不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题而提出的解决方案，所以在数据库中有了MVCC，所以我们可以形成两个组合：</p>
<p>MVCC + 悲观锁MVCC解决读写冲突，悲观锁解决写写冲突</p>
<p>MVCC + 乐观锁MVCC解决读写冲突，乐观锁解决写写冲突</p>
<p>这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题*<u>MYSQL 事务日志</u>*</p>
<p>事务日志可以帮助提高事务的效率。使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。事务日志持久以后，内存中被修改的数据在后台可以慢慢地刷回到磁盘。目前大多数存储引擎都是这样实现的，我们通常称之为预写式日志（Write-Ahead Logging），修改数据需要写两次磁盘。 如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。</p>
<p>MySQL Innodb中跟数据持久性、一致性有关的日志，有以下几种：</p>
<p>**1.**Bin Log:是mysql服务层产生的日志，常用来进行数据恢复、数据库复制，常见的mysql主从架构，就是采用slave同步master的binlog实现的Redo Log:记录了数据操作在物理层面的修改，mysql中使用了大量缓存，修改操作时会直接修改内存，而不是立刻修改磁盘，事务进行中时会不断的产生redo log，在事务提交时进行一次flush操作，保存到磁盘中。当数据库或主机失效重启时，会根据redo log进行数据的恢复，如果redo log中有事务提交，则进行事务提交修改数据。</p>
<p>**<u>2.</u>**Undo Log: 除了记录redo log外，当进行数据修改时还会记录undo log，undo log用于数据的撤回操作，它记录了修改的反向操作，比如，插入对应删除，修改对应修改为原来的数据，通过undo log可以实现事务回滚，并且可以根据undo log回溯到某个特定的版本的数据，实现MVCC</p>
<p><u><em>MVCC的实现原理</em></u></p>
<p>MVCC的目的就是多版本并发控制，在数据库中的实现，就是为了解决读写冲突，它的实现原理主要是依赖记录中的 3个隐式字段，undo日志 ，Read View 来实现的。所以我们先来看看这个三个point的概念隐式字段每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID等字段</p>
<p>DB_TRX_ID 6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务IDDB_ROLL_PTR 7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）DB_ROW_ID 6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了<br>
如上图，DB_ROW_ID是数据库默认为该行记录生成的唯一隐式主键，DB_TRX_ID是当前操作该记录的事务ID,而DB_ROLL_PTR是一个回滚指针，用于配合undo日志，指向上一个旧版本undo日志</p>
<p>undo log主要分为两种：</p>
<p>insert undo log代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃</p>
<p>update undo log事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除purge</p>
<p>从前面的分析可以看出，为了实现InnoDB的MVCC机制，更新或者删除操作都只是设置一下老记录的deleted_bit，并不真正将过时的记录删除。为了节省磁盘空间，InnoDB有专门的purge线程来清理deleted_bit为true的记录。为了不影响MVCC的正常工作，purge线程自己也维护了一个read view（这个read view相当于系统中最老活跃事务的read view）;如果某个记录的deleted_bit为true，并且DB_TRX_ID相对于purge线程的read view可见即当前记录没有相关活跃事务在操作时，那么这条记录一定是可以被安全清除的。对MVCC有帮助的实质是update undo log ，undo log实际上就是存在rollback segment中旧记录链，它的执行流程如下：</p>
<p>一、 比如一个有个事务插入persion表插入了一条新记录，记录如下，name为Jerry, age为24岁，隐式主键是1，事务ID和回滚指针，我们假设为NULL<br>
二、 现在来了一个事务1对该记录的name做出了修改，改为Tom在事务1修改该行(记录)数据时，数据库会先对该行加排他锁然后把该行数据拷贝到undo log中，作为旧记录，既在undo log中有当前行的拷贝副本拷贝完毕后，修改该行name为Tom，并且修改隐藏字段的事务ID为当前事务1的ID, 我们默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，既表示我的上一个版本就是它事务提交后，释放锁</p>
<p>三、 又来了个事务2修改person表的同一个记录，将age修改为30岁在事务2修改该行数据时，数据库也先为该行加锁然后把该行数据拷贝到undo log中，作为旧记录，发现该行记录已经有undo log了，那么最新的旧数据作为链表的表头，插在该行记录的undo log最前面修改该行age为30岁，并且修改隐藏字段的事务ID为当前事务2的ID, 那就是2，回滚指针指向刚刚拷贝到undo log的副本记录事务提交，释放锁<br>
从上面，我们就可以看出，不同事务或者相同事务的对同一记录的修改，会导致该记录的undo log成为一条记录版本线性表，既链表，undo log的链首就是最新的旧记录，链尾就是最早的旧记录（当然就像之前说的该undo log的节点可能是会purge线程清除掉，向图中的第一条insert undo log，其实在事务提交之后可能就被删除丢失了，不过这里为了演示，所以还放在这里）Read View(读视图)</p>
<p><em><u>什么是Read View?</u></em></p>
<p>什么是Read View，说白了Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大)。所以我们知道 Read View主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。</p>
<p>Read View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果DB_TRX_ID跟Read View的属性做了某些比较，不符合可见性，那就通过DB_ROLL_PTR回滚指针去取出Undo Log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的DB_TRX_ID, 那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新老版本那么这个判断条件是什么呢？</p>
<p>如上，它是一段MySQL判断可见性的一段源码，即changes_visible方法（不完全哈，但能看出大致逻辑），该方法展示了我们拿DB_TRX_ID去跟Read View某些属性进行怎么样的比较在展示之前，我先简化一下Read View，我们可以把Read View简单的理解成有三个全局属性。</p>
<p>trx_list（名字我随便取的）一个数值列表，用来维护Read View生成时刻系统正活跃的事务IDup_limit_id记录trx_list列表中事务ID最小的IDlow_limit_idReadView生成时刻系统尚未分配的下一个事务ID，也就是目前已出现过的事务ID的最大值+1，首先比较DB_TRX_ID &lt; up_limit_id, 如果小于，则当前事务能看到DB_TRX_ID 所在的记录，如果大于等于进入下一个判断。接下来判断 DB_TRX_ID 大于等于 low_limit_id , 如果大于等于则代表DB_TRX_ID 所在的记录在Read View生成后才出现的，那对当前事务肯定不可见，如果小于则进入下一个判断判断DB_TRX_ID 是否在活跃事务之中，trx_list.contains(DB_TRX_ID)，如果在，则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是看不见的；如果不在，则说明，你这个事务在Read View生成之前就已经Commit了，你修改的结果，我当前事务是能看见的。</p>
<p>整体流程</p>
<p>我们在了解了隐式字段，undo log， 以及Read View的概念之后，就可以来看看MVCC实现的整体流程是怎么样了整体的流程是怎么样的呢？我们可以模拟一下：</p>
<p>当事务2对某行数据执行了快照读，数据库为该行数据生成一个Read View读视图，假设当前事务ID为2，此时还有事务1和事务3在活跃中，事务4在事务2快照读前一刻提交更新了，所以Read View记录了系统当前活跃事务1，3的ID，维护在一个列表上，假设我们称为trx_list。</p>
<p>事务1事务2事务3事务4事务开始事务开始事务开始事务开始………修改且已提交进行中快照读进行中………</p>
<p>Read View不仅仅会通过一个列表trx_list来维护事务2执行快照读那刻系统正活跃的事务ID，还会有两个属性up_limit_id（记录trx_list列表中事务ID最小的ID），low_limit_id(记录trx_list列表中事务ID最大的ID，也有人说快照读那刻系统尚未分配的下一个事务ID也就是目前已出现过的事务ID的最大值+1，我更倾向于后者 ) ；所以在这里例子中up_limit_id就是1，low_limit_id就是4 + 1 = 5，trx_list集合的值是1,3，Read View如下图：</p>
<p>我们的例子中，只有事务4修改过该行记录，并在事务2执行快照读前，就提交了事务，所以当前该行当前数据的undo log如下图所示；我们的事务2在快照读该行记录的时候，就会拿该行记录的DB_TRX_ID去跟up_limit_id,low_limit_id和活跃事务ID列表(trx_list)进行比较，判断当前事务2能看到该记录的版本是哪个。<br>
所以先拿该记录DB_TRX_ID字段记录的事务ID 4去跟Read View的的up_limit_id比较，看4是否小于up_limit_id(1)，所以不符合条件，继续判断 4 是否大于等于 low_limit_id(5)，也不符合条件，最后判断4是否处于trx_list中的活跃事务, 最后发现事务ID为4的事务不在当前活跃事务列表中, 符合可见性条件，所以事务4修改后提交的最新结果对事务2快照读时是可见的，所以事务2能读到的最新数据记录是事务4所提交的版本，而事务4提交的版本也是全局角度上最新的版本。</p>
<p>也正是Read View生成时机的不同，从而造成RC,RR级别下快照读的结果的不同。</p>
<p><strong><u><em>MVCC相关问题</em></u></strong></p>
<p><u><em>RR是如何在RC级的基础上解决不可重复读的？</em></u></p>
<p>当前读和快照读在RR级别下的区别：</p>
<p>表1:事务A事务B开启事务开启事务快照读(无影响)查询金额为500快照读查询金额为500更新金额为400提交事务select 快照读金额为500select lock in share mode当前读金额为400在上表的顺序下，事务B的在事务A提交修改后的快照读是旧版本数据，而当前读是实时新数据400。</p>
<p>表2:事务A事务B开启事务开启事务快照读（无影响）查询金额为500更新金额为400提交事务select 快照读金额为400select lock in share mode当前读金额为400。</p>
<p>而在表2这里的顺序中，事务B在事务A提交后的快照读和当前读都是实时的新数据400，这是为什么呢？这里与上表的唯一区别仅仅是表1的事务B在事务A修改金额前快照读过一次金额数据，而表2的事务B在事务A修改金额前没有进行过快照读。所以我们知道事务中快照读的结果是非常依赖该事务首次出现快照读的地方，即某个事务中首次出现快照读的地方非常关键，它有决定该事务后续快照读结果的能力，我们这里测试的是更新，同时删除和更新也是一样的，如果事务B的快照读是在事务A操作之后进行的，事务B的快照读也是能读取到最新的数据的。</p>
<p><em><u>RC,RR级别下的InnoDB快照读有什么不同？</u></em></p>
<p>正是Read View生成时机的不同，从而造成RC,RR级别下快照读的结果的不同。在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View, 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个Read View，所以对之后的修改不可见；即RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见。而在RC级别下的，事务中，每次快照读都会新生成一个快照和Read View, 这就是我们在RC级别下的事务中可以看到别的事务提交的更新的原因。</p>
<p><strong><u>MVCC原理：</u></strong></p>
<p>MVCC（ Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用READ COMMITTD、REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程。可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。 READ COMMITTD、 REPEATABLE READ这两个隔离级别的一个很大不同就是：生成ReadView的时机不同， READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。</p>
<!-- more -->
]]></content>
    </entry>
</feed>